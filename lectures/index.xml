<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computational Topology Lectures on Dibyajyoti Jena</title>
    <link>https://coolman-spaceman.github.io/lectures/</link>
    <description>Recent content in Computational Topology Lectures on Dibyajyoti Jena</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Jun 2023 18:52:07 +0530</lastBuildDate><atom:link href="https://coolman-spaceman.github.io/lectures/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Introduction to K-Means</title>
      <link>https://coolman-spaceman.github.io/lectures/lec1/</link>
      <pubDate>Fri, 30 Jun 2023 18:52:07 +0530</pubDate>
      
      <guid>https://coolman-spaceman.github.io/lectures/lec1/</guid>
      <description>This tutorial assumes some familiarity with basic principles of machine learning, the math and code can be developed on the way.
Machine Learning Learning can be Supervised, Unsupervised, Reinforced and Semi-supervised.
 Reinforcement Learning: Learning with a critic, critic may be wrong at times, maybe stochastic, but different from supervisor in case of supervised learning. Supervisor gives feedback, critic only says yes or no.
 K-Means algorithm:  K as a parameter distance threshold as a parameter  K means crisp decision boundary: grading, fingerprint ROI(Region of Interest)</description>
    </item>
    
  </channel>
</rss>
